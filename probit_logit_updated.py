# -*- coding: utf-8 -*-
"""Probit-Logit-updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1En7ewg1BD_InatOcHe2R9S4BzHfJntkN
"""

#Code to conduct Probit statistics for toxicological experiments.

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
from scipy.stats import norm  # Import the norm function
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy.stats import chi2
import seaborn as sns

#Ensure to remove zero concentration treatment. Calculate corrected mortality and include that data here.
data = {
    'CONC': [1,3,5,7,10,15],
    'N': [30,30,30,30,30,30],
    'DEAD': [4,13,22,24,30,30]
}

# Create a list with binomial responses based on 'DEAD' and 'N'
response_list = []
for i in range(len(data['CONC'])):
    dead_count = data['DEAD'][i]
    alive_count = data['N'][i] - dead_count
    response_list.extend([1] * dead_count + [0] * alive_count)

# Create a new dataframe
df = pd.DataFrame({
    'CONC': np.repeat(data['CONC'], data['N']),
    'DEAD': response_list
})

# Add a constant term to the independent variables
df['const'] = 1

# Fit the probit model
X = df[['const', 'CONC']]
y = df['DEAD']
model = sm.Probit(y, X)
result = model.fit()

# Display the model summary
print(result.summary())

# Assuming predicted probits is the column you want to plot
df['log_CONC'] = np.log10(df['CONC'])
df['predicted_probits'] = result.predict()

# Goodness of fit estimates
deviance_residuals = result.resid_dev
deviance_chi_square = np.sum(deviance_residuals**2)
p_value = 1 - chi2.cdf(deviance_chi_square, df=result.df_resid)

print(f'Deviance Chi-Square: {deviance_chi_square:.4f}')
print(f'Goodness of Fit p-value: {p_value:.4f}')

# Calculate regression equation
slope, intercept, r_value, p_value, std_err = linregress(df['log_CONC'], df['predicted_probits'])
regression_equation = f'y = {slope:.4f} * x + {intercept:.4f}'
print('Regression Equation (log scale):', regression_equation)



# Calculate 'CONC' values for predicted probits of 0.5, 0.95, and 0.99
probit_levels = [0.25,0.5, 0.95, 0.99]
conc_values = {}
conf_intervals = {}

for probit_level in probit_levels:
    # Calculate 'CONC' value using back-transformed regression equation
    conc_value = 10 ** ((probit_level - intercept) / slope)
    conc_values[f'CONC_{int(probit_level * 100)}'] = conc_value

    # Calculate confidence intervals at 95% confidence interval
    stderr_margin = norm.ppf(0.975) * std_err #for 90% CI replace 0.975 with 0.95; for 80% CI replace with 0.90
    lower_bound = 10 ** ((probit_level - intercept - stderr_margin) / slope)
    upper_bound = 10 ** ((probit_level - intercept + stderr_margin) / slope)
    conf_intervals[f'CONC_{int(probit_level * 100)}'] = (lower_bound, upper_bound)

# Display the calculated 'CONC' values and confidence intervals
for level, value in conc_values.items():
   print(f'{level}: {value:.4f}')

for level, interval in conf_intervals.items():
   print(f'{level} 95% Confidence Interval: ({interval[0]:.4f}, {interval[1]:.4f})')
   #print(f'{level}: {value:.4f}', f'(95% Confidence Interval: {interval[0]:.4f}, {interval[1]:.4f})')

# Plot log10 of 'CONC' against 'PROP-1 probits'
plt.scatter(df['log_CONC'], df['predicted_probits'], label='Probit Model')
#plt.xscale('log')

plt.title('Probit Model: log10(CONC) vs Mortality proportion probits')

# Add linear regression line
#slope, intercept, r_value, p_value, std_err = linregress(data['log_CONC'], data['predicted_probits'])
#linear_regression_line = slope * data['log_CONC'] + intercept
#plt.plot(data['log_CONC'], linear_regression_line, color='red')
sns.regplot(x='log_CONC', y='predicted_probits',data=df)
plt.show()

#Code to conduct Logit statistics for toxicological experiments.

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
from scipy.stats import norm  # Import the norm function
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy.stats import chi2
import seaborn as sns

#Ensure to remove zero concentration treatment. Calculate corrected mortality and include that data here.
data = {
    'CONC': [1,3,5,7,10,15],
    'N': [30,30,30,30,30,30],
    'DEAD': [4,13,22,24,30,30]
}

# Create a list with binomial responses based on 'DEAD' and 'N'
response_list = []
for i in range(len(data['CONC'])):
    dead_count = data['DEAD'][i]
    alive_count = data['N'][i] - dead_count
    response_list.extend([1] * dead_count + [0] * alive_count)

# Create a new dataframe
df = pd.DataFrame({
    'CONC': np.repeat(data['CONC'], data['N']),
    'DEAD': response_list
})

# Add a constant term to the independent variables
df['const'] = 1

# Fit the probit model
X = df[['const', 'CONC']]
y = df['DEAD']
model = sm.Logit(y, X)
result = model.fit()

# Display the model summary
print(result.summary())

# Assuming predicted probits is the column you want to plot
df['log_CONC'] = np.log10(df['CONC'])
df['predicted_logits'] = result.predict()

# Goodness of fit estimates
deviance_residuals = result.resid_dev
deviance_chi_square = np.sum(deviance_residuals**2)
p_value = 1 - chi2.cdf(deviance_chi_square, df=result.df_resid)

print(f'Deviance Chi-Square: {deviance_chi_square:.4f}')
print(f'Goodness of Fit p-value: {p_value:.4f}')

# Calculate regression equation
slope, intercept, r_value, p_value, std_err = linregress(df['log_CONC'], df['predicted_logits'])
regression_equation = f'y = {slope:.4f} * x + {intercept:.4f}'
print('Regression Equation (log scale):', regression_equation)



# Calculate 'CONC' values for predicted probits of 0.5, 0.95, and 0.99
probit_levels = [0.25,0.5, 0.95, 0.99]
conc_values = {}
conf_intervals = {}

for probit_level in probit_levels:
    # Calculate 'CONC' value using back-transformed regression equation
    conc_value = 10 ** ((probit_level - intercept) / slope)
    conc_values[f'CONC_{int(probit_level * 100)}'] = conc_value

    # Calculate confidence intervals at 95% confidence interval
    stderr_margin = norm.ppf(0.975) * std_err #for 90% CI replace 0.975 with 0.95; for 80% CI replace with 0.90
    lower_bound = 10 ** ((probit_level - intercept - stderr_margin) / slope)
    upper_bound = 10 ** ((probit_level - intercept + stderr_margin) / slope)
    conf_intervals[f'CONC_{int(probit_level * 100)}'] = (lower_bound, upper_bound)

# Display the calculated 'CONC' values and confidence intervals
for level, value in conc_values.items():
   print(f'{level}: {value:.4f}')

for level, interval in conf_intervals.items():
   print(f'{level} 95% Confidence Interval: ({interval[0]:.4f}, {interval[1]:.4f})')
   #print(f'{level}: {value:.4f}', f'(95% Confidence Interval: {interval[0]:.4f}, {interval[1]:.4f})')

# Plot log10 of 'CONC' against 'PROP-1 probits'
plt.scatter(df['log_CONC'], df['predicted_logits'], label='Logit Model')
#plt.xscale('log')

plt.title('Logit Model: log10(CONC) vs Mortality proportion logits')

# Add linear regression line
#slope, intercept, r_value, p_value, std_err = linregress(data['log_CONC'], data['predicted_probits'])
#linear_regression_line = slope * data['log_CONC'] + intercept
#plt.plot(data['log_CONC'], linear_regression_line, color='red')
sns.regplot(x='log_CONC', y='predicted_logits',data=df)
plt.show()