# -*- coding: utf-8 -*-
"""Data_transformation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lhb6vqHkqh48WhhJDeinbs-qo_eKYsH_
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pandas statsmodels scipy openpyxl tabulate

import pandas as pd
import statsmodels.api as sm
import numpy as np
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from scipy import stats
from tabulate import tabulate

from google.colab import files

uploaded = files.upload()

filename = next(iter(uploaded))
df = pd.read_excel(filename)
print("First 5 rows of the DataFrame:")
display(df.head())
print("\nColumn names of the DataFrame:")
print(df.columns)

while True:
    block_col = input("Enter the name of the column for blocks: ")
    if block_col not in df.columns:
        print(f"Error: Column '{block_col}' not found in the data. Please try again.")
        continue
    break

while True:
    factor_cols_input = input("Enter the names of columns for factors (up to three, comma-separated): ")
    factor_cols = [col.strip() for col in factor_cols_input.split(',')]
    invalid_factors = [col for col in factor_cols if col not in df.columns]
    if invalid_factors:
        print(f"Error: The following factor columns were not found: {', '.join(invalid_factors)}. Please try again.")
        continue
    if len(factor_cols) > 3:
        print("Error: Please enter up to three factor columns. Please try again.")
        continue
    break

while True:
    response_col = input("Enter the name of the column for the response variable: ")
    if response_col not in df.columns:
        print(f"Error: Column '{response_col}' not found in the data. Please try again.")
        continue
    break

print(f"\nSelected columns:")
print(f"Blocks: {block_col}")
print(f"Factors: {', '.join(factor_cols)}")
print(f"Response: {response_col}")

# Select relevant columns
selected_cols = [block_col] + factor_cols + [response_col]
df_processed = df[selected_cols].copy()

# Check for missing values in selected columns
if df_processed.isnull().any().any():
    print("Missing values found in the selected columns.")
    # Drop rows with missing values
    initial_rows = df_processed.shape[0]
    df_processed.dropna(inplace=True)
    rows_dropped = initial_rows - df_processed.shape[0]
    print(f"Dropped {rows_dropped} row(s) with missing values.")
else:
    print("No missing values found in the selected columns.")

# Ensure data types are appropriate
# Block and factor columns should be categorical/object
for col in [block_col] + factor_cols:
    if not pd.api.types.is_categorical_dtype(df_processed[col]) and not pd.api.types.is_object_dtype(df_processed[col]):
        print(f"Warning: Column '{col}' is not of categorical or object type. Attempting to convert to object.")
        df_processed[col] = df_processed[col].astype(str) # Convert to string as a safe default

# Response variable should be numeric
try:
    df_processed[response_col] = pd.to_numeric(df_processed[response_col])
except ValueError as e:
    print(f"Error: Could not convert response column '{response_col}' to numeric. Please check for non-numeric entries.")
    print(f"Details: {e}")
    # Handle error - for now, we'll just stop here if conversion fails.
    # In a real application, you might want to give the user options to inspect/clean.
    raise # Re-raise the exception to stop execution

# Display preview of processed data
print("\nPreview of processed data:")
display(df_processed.head())

# Print shape of processed data
print("\nShape of processed data (rows, columns):")
print(df_processed.shape)

print("\n--- Data Transformation Options ---")
print("If the ANOVA assumptions were not met based on the plots and/or formal tests, you might consider transforming the response variable.")
print("Common transformations include:")
print("1. Log transformation (useful for right-skewed data or when variances increase with the mean)")
print("2. Square root transformation (useful for count data or when variances are proportional to the mean)")
print("3. Reciprocal transformation (1/x) (useful for data with a large range or when variances increase sharply with the mean)")
print("4. No transformation (proceed with the original data)")
df_processed = df[selected_cols].copy()

while True:
    transform_choice = input("Enter the number of the transformation you want to apply (1-4): ")
    if transform_choice in ['1', '2', '3', '4']:
        break
    else:
        print("Invalid choice. Please enter a number between 1 and 4.")

# Apply the chosen transformation to a copy of the processed data
df_transformed = df_processed.copy()
original_response_col = response_col # Store original name

if transform_choice == '1':
    # Add a small constant (e.g., 1) before log transformation if data includes 0 or negative values
    # For this example, assuming positive response values based on the dataset preview.
    # In a real application, you might want to add a check or user input for handling zeros/negatives.
    try:
        df_transformed[response_col] = df_transformed[response_col].apply(lambda x: log(x + 1) if x >= 0 else log(x)) # log(x+1) for non-negative, log(x) for negative
        response_col = f"Log_{original_response_col}" # Update response column name
        print(f"\n'{original_response_col}' transformed using Log. New column name: '{response_col}'")
    except Exception as e:
        print(f"Error applying log transformation: {e}")
        print("Please ensure your response variable does not contain non-positive values if using log(x).")
        # Revert to original data if transformation fails
        df_transformed = df_processed.copy()
        response_col = original_response_col
        print("Transformation failed. Reverting to original data.")


elif transform_choice == '2':
    try:
        # Ensure values are non-negative for square root transformation
        if (df_transformed[response_col] < 0).any():
             print("Error: Square root transformation cannot be applied to negative values.")
             # Revert to original data if transformation not possible
             df_transformed = df_processed.copy()
             response_col = original_response_col
             print("Transformation skipped. Reverting to original data.")
        else:
            df_transformed[response_col] = np.sqrt(df_transformed[response_col])
            response_col = f"Sqrt_{original_response_col}" # Update response column name
            print(f"\n'{original_response_col}' transformed using Square Root. New column name: '{response_col}'")
    except Exception as e:
        print(f"Error applying square root transformation: {e}")
        # Revert to original data if transformation fails
        df_transformed = df_processed.copy()
        response_col = original_response_col
        print("Transformation failed. Reverting to original data.")


elif transform_choice == '3':
    try:
        # Handle zero values before reciprocal transformation
        if (df_transformed[response_col] == 0).any():
             print("Error: Reciprocal transformation (1/x) cannot be applied to zero values.")
             # Revert to original data if transformation not possible
             df_transformed = df_processed.copy()
             response_col = original_response_col
             print("Transformation skipped. Reverting to original data.")
        else:
            df_transformed[response_col] = 1 / df_transformed[response_col]
            response_col = f"Reciprocal_{original_response_col}" # Update response column name
            print(f"\n'{original_response_col}' transformed using Reciprocal. New column name: '{response_col}'")
    except Exception as e:
        print(f"Error applying reciprocal transformation: {e}")
        # Revert to original data if transformation fails
        df_transformed = df_processed.copy()
        response_col = original_response_col
        print("Transformation failed. Reverting to original data.")

else: # transform_choice == '4'
    df_transformed = df_processed.copy()
    response_col = original_response_col
    print("\nNo transformation applied. Proceeding with original data.")

# Display preview of the potentially transformed data
print("\nPreview of data after transformation:")
display(df_transformed.head())

# Now, you would typically re-run the ANOVA and post-hoc tests using df_transformed and the updated response_col
# The subsequent cells in the notebook would need to use df_transformed and the potentially new response_col name.
# For this script structure, you would likely copy and paste the ANOVA and post-hoc cells below this.

# Note: For a fully interactive script, you might want to wrap the entire analysis part
# into a function that takes the dataframe and response column name as arguments.